


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>neural_compressor.adaptor.onnxrt &mdash; Intel® Neural Compressor  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

  
<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <div class="navbar-logo">
          <a href="https://intel.github.io/neural-compressor/Welcome.html" alt="Intel homepage" class="intel-logo-rebrand">
            <span class="headTitleStyle"> Intel® Neural Compressor</span> 
          </a>
        <div class="version">
              <a href="../../../../../versions.html">2.0▼</a>
              <p>Click link above to switch version</p>
            </div>
    </div>
      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
   

          </div>

          

            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Welcome.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.onnxrt</span></code></li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../../../_sources/autoapi/neural_compressor/adaptor/onnxrt/index.rst.txt" rel="nofollow"><img src="../../../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <section id="module-neural_compressor.adaptor.onnxrt">
<span id="neural-compressor-adaptor-onnxrt"></span><h1><a class="reference internal" href="#module-neural_compressor.adaptor.onnxrt" title="neural_compressor.adaptor.onnxrt"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.onnxrt</span></code></a><a class="headerlink" href="#module-neural_compressor.adaptor.onnxrt" title="Permalink to this heading">¶</a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading">¶</a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">¶</a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_QLinearOpsAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_IntegerOpsAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRT_QDQAdaptor</span></code></a></p></td>
<td><p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery" title="neural_compressor.adaptor.onnxrt.ONNXRTQuery"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRTQuery</span></code></a></p></td>
<td><p>Base class that defines Query Interface.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRUNTIMEAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../adaptor/index.html#neural_compressor.adaptor.adaptor.Adaptor" title="neural_compressor.adaptor.adaptor.Adaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.adaptor.Adaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>The function is used to do calibration and quanitization in post-training</dt><dd><p>quantization.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – quantization config.</p></li>
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>data_loader</strong> (<em>object</em>) – calibration dataset.</p></li>
<li><p><strong>q_func</strong> (<em>optional</em>) – training function for quantization aware training mode,
unimplement yet for onnx.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover">
<span class="sig-name descname"><span class="pre">recover</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the recover process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>q_config</strong> (<em>dict</em>) – recover configuration</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor">
<span class="sig-name descname"><span class="pre">inspect_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inspect_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'activation'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_to_disk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantization_cfg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for dumping tensor info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor">
<span class="sig-name descname"><span class="pre">set_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for setting tensor back to model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to set tensor. Usually it is quantized model.</p></li>
<li><p><strong>tensor_dict</strong> (<em>dict</em>) – <p>The tensor dict to set. Note the numpy array contains float
value, adaptor layer has the responsibility to quantize to
int8 or int32 to set into the quantized model if needed.
The dict format is something like:
{</p>
<blockquote>
<div><p>’weight0_name’: numpy.array,
‘bias0_name’: numpy.array,
…</p>
</div></blockquote>
<p>}</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability">
<span class="sig-name descname"><span class="pre">query_fw_capability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used to query framework capability.
TODO: will be replaced by framework query API</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> – onnx model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantization capability</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_graph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measurer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp32_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is for evaluation if no given eval func</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_graph</strong> – onnx model for evaluation</p></li>
<li><p><strong>dataloader</strong> – dataloader for evaluation. neural_compressor.data.dataloader.ONNXDataLoader</p></li>
<li><p><strong>postprocess</strong> – post-process for evalution. neural_compressor.data.transform.ONNXTransforms</p></li>
<li><p><strong>metrics</strong> – : metrics for evaluation. neural_compressor.metric.ONNXMetrics</p></li>
<li><p><strong>measurer</strong> – neural_compressor.objective.Measurer</p></li>
<li><p><strong>iteration</strong> (<em>int</em>) – max iterations of evaluaton.</p></li>
<li><p><strong>tensorboard</strong> (<em>bool</em>) – whether to use tensorboard for visualizaton</p></li>
<li><p><strong>fp32_baseline</strong> (<em>boolen</em><em>, </em><em>optional</em>) – only for compare_label=False pipeline</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(float) evaluation results. acc, f1 e.g.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>save model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>ModelProto</em>) – model to save</p></li>
<li><p><strong>path</strong> (<em>str</em>) – save path</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_QLinearOpsAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_IntegerOpsAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRT_QDQAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor" title="neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a></p>
<p>The ONNXRT adaptor layer, do onnx-rt quantization, calibration, inspect layer tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – framework specific configuration for quantization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.onnxrt.</span></span><span class="sig-name descname"><span class="pre">ONNXRTQuery</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../query/index.html#neural_compressor.adaptor.query.QueryBackendCapability" title="neural_compressor.adaptor.query.QueryBackendCapability"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.query.QueryBackendCapability</span></code></a></p>
<p>Base class that defines Query Interface.
Each adaption layer should implement the inherited class for specific backend on their own.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version">
<span class="sig-name descname"><span class="pre">get_version</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the current backend version infomation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>version string.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[string]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions">
<span class="sig-name descname"><span class="pre">get_precisions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get supported precisions for current backend.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the precisions’ name.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[string list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types">
<span class="sig-name descname"><span class="pre">get_op_types</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types by all precisions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of dictionary which key is precision
and value is the op types.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability">
<span class="sig-name descname"><span class="pre">get_quantization_capability</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types’ quantization capability.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of dictionary which key is precision
and value is a dict that describes all op types’ quantization capability.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision">
<span class="sig-name descname"><span class="pre">get_op_types_by_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Get op types per precision</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>precision</strong> (<em>string</em>) – precision name</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list composed of op type.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>[string list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization">
<span class="sig-name descname"><span class="pre">get_graph_optimization</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Get onnxruntime graph optimization level</p>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Intel® Neural Compressor.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.onnxrt</span></code></a><ul>
<li><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li><a class="reference internal" href="#classes">Classes</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.quantize()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.recover()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.inspect_tensor()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.set_tensor()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.query_fw_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save"><code class="docutils literal notranslate"><span class="pre">ONNXRUNTIMEAdaptor.save()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor"><code class="docutils literal notranslate"><span class="pre">ONNXRT_QLinearOpsAdaptor</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor"><code class="docutils literal notranslate"><span class="pre">ONNXRT_IntegerOpsAdaptor</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor"><code class="docutils literal notranslate"><span class="pre">ONNXRT_QDQAdaptor</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_version()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_precisions()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_op_types()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_quantization_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_op_types_by_precision()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization"><code class="docutils literal notranslate"><span class="pre">ONNXRTQuery.get_graph_optimization()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor">ONNXRUNTIMEAdaptor</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.quantize">quantize</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.recover">recover</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.inspect_tensor">inspect_tensor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.set_tensor">set_tensor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.query_fw_capability">query_fw_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.evaluate">evaluate</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor.save">save</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor">ONNXRT_QLinearOpsAdaptor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor">ONNXRT_IntegerOpsAdaptor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor">ONNXRT_QDQAdaptor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery">ONNXRTQuery</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_version">get_version</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_precisions">get_precisions</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types">get_op_types</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_quantization_capability">get_quantization_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_op_types_by_precision">get_op_types_by_precision</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.onnxrt.ONNXRTQuery.get_graph_optimization">get_graph_optimization</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../../_static/sphinx_highlight.js"></script>

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
<script script type="text/javascript">
  var collapsedSections = ['start', 'autoapi', 'info'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>