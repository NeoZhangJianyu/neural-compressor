


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>neural_compressor.adaptor.pytorch &mdash; Intel® Neural Compressor  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/features">Features</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

  
<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <div class="navbar-logo">
          <a href="https://intel.github.io/neural-compressor/Welcome.html" alt="Intel homepage" class="intel-logo-rebrand">
            <span class="headTitleStyle"> Intel® Neural Compressor</span> 
          </a>
        <div class="version">
              <a href="../../../../../versions.html">2.0▼</a>
              <p>Click link above to switch version</p>
            </div>
    </div>
      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
   

          </div>

          

            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Welcome.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.pytorch</span></code></li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../../../_sources/autoapi/neural_compressor/adaptor/pytorch/index.rst.txt" rel="nofollow"><img src="../../../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <section id="module-neural_compressor.adaptor.pytorch">
<span id="neural-compressor-adaptor-pytorch"></span><h1><a class="reference internal" href="#module-neural_compressor.adaptor.pytorch" title="neural_compressor.adaptor.pytorch"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.pytorch</span></code></a><a class="headerlink" href="#module-neural_compressor.adaptor.pytorch" title="Permalink to this heading">¶</a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading">¶</a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">¶</a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor" title="neural_compressor.adaptor.pytorch.TemplateAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TemplateAdaptor</span></code></a></p></td>
<td><p>Tample adaptor of PyTorch framework.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor" title="neural_compressor.adaptor.pytorch.PyTorchAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PyTorchAdaptor</span></code></a></p></td>
<td><p>Adaptor of PyTorch framework, all PyTorch API is in this class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor" title="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor</span></code></a></p></td>
<td><p>Adaptor of PyTorch framework with Intel PyTorch Extension,</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor" title="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor</span></code></a></p></td>
<td><p>Adaptor of PyTorch framework with FX graph mode, all PyTorch API is in this class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery" title="neural_compressor.adaptor.pytorch.PyTorchQuery"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PyTorchQuery</span></code></a></p></td>
<td><p>Base class that defines Query Interface.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this heading">¶</a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#neural_compressor.adaptor.pytorch.get_ops_recursively" title="neural_compressor.adaptor.pytorch.get_ops_recursively"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_ops_recursively</span></code></a>(model, prefix[, ops])</p></td>
<td><p>This is a helper function for <cite>graph_info</cite>,</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.get_ops_recursively">
<span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">get_ops_recursively</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ops</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.get_ops_recursively" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>This is a helper function for <cite>graph_info</cite>,</dt><dd><p>and it will get all ops from model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – input model</p></li>
<li><p><strong>prefix</strong> (<em>string</em>) – prefix of op name</p></li>
<li><p><strong>ops</strong> (<em>dict</em>) – dict of ops from model {op name: type}.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.TemplateAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">TemplateAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../adaptor/index.html#neural_compressor.adaptor.adaptor.Adaptor" title="neural_compressor.adaptor.adaptor.Adaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.adaptor.Adaptor</span></code></a></p>
<p>Tample adaptor of PyTorch framework.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – dictionary of tuning configure from yaml file.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.TemplateAdaptor.is_fused_module">
<span class="sig-name descname"><span class="pre">is_fused_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.is_fused_module" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>This is a helper function for <cite>_propagate_qconfig_helper</cite> to detecte</dt><dd><p>if this module is fused.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>module</strong> (<em>object</em>) – input module</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>is fused or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.TemplateAdaptor.calculate_hessian_trace">
<span class="sig-name descname"><span class="pre">calculate_hessian_trace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fp32_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_act</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.calculate_hessian_trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate hessian trace.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fp32_model</strong> – The original fp32 model.</p></li>
<li><p><strong>criterion</strong> – The loss function for calculate the hessian trace. # loss = criterion(output, target)</p></li>
<li><p><strong>dataloader</strong> – The dataloader for calculate the gradient.</p></li>
<li><p><strong>q_model</strong> – The INT8 AMAP model.</p></li>
<li><p><strong>enable_act</strong> – Enabling quantization error or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(op_name, op_type); value: hessian trace.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hessian_trace(Dict[Tuple, float]), key</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">PyTorchAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor" title="neural_compressor.adaptor.pytorch.TemplateAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TemplateAdaptor</span></code></a></p>
<p>Adaptor of PyTorch framework, all PyTorch API is in this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – dictionary of tuning configure from yaml file.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.quantize" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the quantize process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – quantization config.</p></li>
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – calibration dataset.</p></li>
<li><p><strong>q_func</strong> (<em>objext</em><em>, </em><em>optional</em>) – training function for quantization aware training mode.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(object)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measurer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp32_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the evaluate process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model to run evaluation.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – evaluation dataset.</p></li>
<li><p><strong>postprocess</strong> (<em>object</em><em>, </em><em>optional</em>) – process function after evaluation.</p></li>
<li><p><strong>metrics</strong> (<em>list</em><em>, </em><em>optional</em>) – list of metric function.</p></li>
<li><p><strong>measurer</strong> (<em>object</em><em>, </em><em>optional</em>) – measurer function.</p></li>
<li><p><strong>iteration</strong> (<em>int</em><em>, </em><em>optional</em>) – number of iterations to evaluate.</p></li>
<li><p><strong>tensorboard</strong> (<em>bool</em><em>, </em><em>optional</em>) – dump output tensor to tensorboard summary files.</p></li>
<li><p><strong>fp32_baseline</strong> (<em>boolen</em><em>, </em><em>optional</em>) – only for compare_label=False pipeline</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>accuracy</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(object)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hooks</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the train process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model to run evaluation.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – training dataset.</p></li>
<li><p><strong>optimizer</strong> (<em>tuple</em>) – It is a tuple of (cls, parameters) for optimizer.</p></li>
<li><p><strong>criterion</strong> (<em>tuple</em>) – It is a tuple of (cls, parameters) for criterion.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – other parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_child">
<span class="sig-name descname"><span class="pre">is_fused_child</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_child" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function for <cite>_post_eval_hook</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>op_name</strong> (<em>string</em>) – op name</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>if this op is fused</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_op">
<span class="sig-name descname"><span class="pre">is_fused_op</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_op" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function for <cite>_post_eval_hook</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>op_name</strong> (<em>string</em>) – op name</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>if this op is fused</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_last_fused_child">
<span class="sig-name descname"><span class="pre">is_last_fused_child</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_last_fused_child" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function for <cite>_post_eval_hook</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>op_name</strong> (<em>string</em>) – op name</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>if this op is last fused op</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for saving model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to saved.</p></li>
<li><p><strong>path</strong> (<em>string</em>) – The path where to save.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.inspect_tensor">
<span class="sig-name descname"><span class="pre">inspect_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inspect_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'activation'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_to_disk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.inspect_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for dumping tensor info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to inspect.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – The dataloader used to feed into.</p></li>
<li><p><strong>op_list</strong> (<em>list</em>) – The op name in the fp32 model for dumpping.</p></li>
<li><p><strong>iteration_list</strong> (<em>list</em>) – The iteration list containing iterations to dump.</p></li>
<li><p><strong>inspect_type</strong> (<em>str</em>) – The valid value are ‘weight’, ‘activation’, ‘all’.</p></li>
<li><p><strong>save_to_disk</strong> (<em>bool</em>) – Save to disk or memory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Numpy Array Dict
{</p>
<blockquote>
<div><dl class="simple">
<dt>’weight’: {</dt><dd><p>‘node0_name’: {‘weight0_name’: numpy.array, ‘bias0_name’: numpy.array, …},
‘node1_name’: {‘weight1_name’: numpy.array, ‘bias1_name’: numpy.array, …},
…</p>
</dd>
</dl>
<p>},
‘activation’: [</p>
<blockquote>
<div><p># iter 0
{</p>
<blockquote>
<div><p>’node0_name’: {‘output0_name’: numpy.array, ‘output1_name’: numpy.array, …}
‘node1_name’: {‘output1_name’: numpy.array, ‘output1_name’: numpy.array, …}
…</p>
</div></blockquote>
<p>},
# iter 1
…</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.set_tensor">
<span class="sig-name descname"><span class="pre">set_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor_dict</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.set_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for setting tensor back to model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to set tensor. Usually it is quantized model.</p></li>
<li><p><strong>tensor_dict</strong> (<em>dict</em>) – <p>The tensor dict to set. Note the numpy array contains float
value, adaptor layer has the responsibility to quantize to
int8 or int32 to set into the quantized model if needed.
The dict format is something like:
{</p>
<blockquote>
<div><p>’weight0_name’: numpy.array,
‘bias0_name’: numpy.array,
…</p>
</div></blockquote>
<p>}</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.query_fw_capability">
<span class="sig-name descname"><span class="pre">query_fw_capability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.query_fw_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function to get all quantizable ops from model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>object</em>) – input model which is Neural Compressor model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tuning capability for each op from model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>q_capability (dictionary)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchAdaptor.get_non_quant_modules">
<span class="sig-name descname"><span class="pre">get_non_quant_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.get_non_quant_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function to get all non_quant_modules from customer and default.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_kwargs</strong> (<em>dictionary</em>) – keyword args from Neural Compressor model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>non_quant_modules for model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>custom_non_quant_dict (dictionary)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">PyTorch_IPEXAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor" title="neural_compressor.adaptor.pytorch.TemplateAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TemplateAdaptor</span></code></a></p>
<dl class="simple">
<dt>Adaptor of PyTorch framework with Intel PyTorch Extension,</dt><dd><p>all PyTorch IPEX API is in this class.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – dictionary of tuning configure from yaml file.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.quantize" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the quantize process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – quantization config.</p></li>
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization, it is Neural Compressor model.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – calibration dataset.</p></li>
<li><p><strong>q_func</strong> (<em>objext</em><em>, </em><em>optional</em>) – training function for quantization aware training mode.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measurer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp32_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the evaluate process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – Neural Compressor model to run evaluation.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – evaluation dataset.</p></li>
<li><p><strong>postprocess</strong> (<em>object</em><em>, </em><em>optional</em>) – process function after evaluation.</p></li>
<li><p><strong>metrics</strong> (<em>list</em><em>, </em><em>optional</em>) – list of metric function.</p></li>
<li><p><strong>measurer</strong> (<em>object</em><em>, </em><em>optional</em>) – measurer function.</p></li>
<li><p><strong>iteration</strong> (<em>int</em><em>, </em><em>optional</em>) – number of iterations to evaluate.</p></li>
<li><p><strong>tensorboard</strong> (<em>bool</em><em>, </em><em>optional</em>) – dump output tensor to tensorboard summary
files(IPEX unspport).</p></li>
<li><p><strong>fp32_baseline</strong> (<em>boolen</em><em>, </em><em>optional</em>) – only for compare_label=False pipeline</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(dict)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.query_fw_capability">
<span class="sig-name descname"><span class="pre">query_fw_capability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.query_fw_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function to get all quantizable ops from model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>object</em>) – input model which is Neural Compressor model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tuning capability for each op from model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>q_capability (dictionary)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.save" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for set best configure in Neural Compressor model.</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>model (object): The Neural Compressor model which is best results.
path (string): No used.</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.inspect_tensor">
<span class="sig-name descname"><span class="pre">inspect_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">op_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inspect_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'activation'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_to_disk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.inspect_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The function is used by tune strategy class for dumping tensor info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – The model to inspect.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – The dataloader used to feed into.</p></li>
<li><p><strong>op_list</strong> (<em>list</em>) – The op name in the fp32 model for dumpping.</p></li>
<li><p><strong>iteration_list</strong> (<em>list</em>) – The iteration list containing iterations to dump.</p></li>
<li><p><strong>inspect_type</strong> (<em>str</em>) – The valid value are ‘weight’, ‘activation’, ‘all’.</p></li>
<li><p><strong>save_to_disk</strong> (<em>bool</em>) – Save to disk or memory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Numpy Array Dict
{</p>
<blockquote>
<div><dl class="simple">
<dt>’weight’: {</dt><dd><p>‘node0_name’: {‘weight0_name’: numpy.array, ‘bias0_name’: numpy.array, …},
‘node1_name’: {‘weight1_name’: numpy.array, ‘bias1_name’: numpy.array, …},
…</p>
</dd>
</dl>
<p>},
‘activation’: [</p>
<blockquote>
<div><p># iter 0
{</p>
<blockquote>
<div><p>’node0_name’: {‘output0_name’: numpy.array, ‘output1_name’: numpy.array, …}
‘node1_name’: {‘output1_name’: numpy.array, ‘output1_name’: numpy.array, …}
…</p>
</div></blockquote>
<p>},
# iter 1
…</p>
</div></blockquote>
<p>]</p>
</div></blockquote>
<p>}</p>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">PyTorch_FXAdaptor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework_specific_info</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor" title="neural_compressor.adaptor.pytorch.TemplateAdaptor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TemplateAdaptor</span></code></a></p>
<p>Adaptor of PyTorch framework with FX graph mode, all PyTorch API is in this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>framework_specific_info</strong> (<em>dict</em>) – dictionary of tuning configure from yaml file.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.quantize">
<span class="sig-name descname"><span class="pre">quantize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.quantize" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the quantize process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – quantization config.</p></li>
<li><p><strong>model</strong> (<em>object</em>) – model need to do quantization.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – calibration dataset.</p></li>
<li><p><strong>q_func</strong> (<em>objext</em><em>, </em><em>optional</em>) – training function for quantization aware training mode.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>quantized model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(object)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">postprocess</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">measurer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iteration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fp32_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the evaluate process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model to run evaluation.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – evaluation dataset.</p></li>
<li><p><strong>postprocess</strong> (<em>object</em><em>, </em><em>optional</em>) – process function after evaluation.</p></li>
<li><p><strong>metric</strong> (<em>object</em><em>, </em><em>optional</em>) – metric function.</p></li>
<li><p><strong>measurer</strong> (<em>object</em><em>, </em><em>optional</em>) – measurer function.</p></li>
<li><p><strong>iteration</strong> (<em>int</em><em>, </em><em>optional</em>) – number of iterations to evaluate.</p></li>
<li><p><strong>tensorboard</strong> (<em>bool</em><em>, </em><em>optional</em>) – dump output tensor to tensorboard summary files.</p></li>
<li><p><strong>fp32_baseline</strong> (<em>boolen</em><em>, </em><em>optional</em>) – only for compare_label=False pipeline</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>accuracy</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(object)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hooks</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute the train process on the specified model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – model to run evaluation.</p></li>
<li><p><strong>dataloader</strong> (<em>object</em>) – training dataset.</p></li>
<li><p><strong>optimizer</strong> (<em>tuple</em>) – It is a tuple of (cls, parameters) for optimizer.</p></li>
<li><p><strong>criterion</strong> (<em>tuple</em>) – It is a tuple of (cls, parameters) for criterion.</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – other parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.prepare_sub_graph">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prepare_sub_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sub_module_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fx_op_cfgs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_qat</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.prepare_sub_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method to prepare sub modules recursively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sub_module_list</strong> (<em>list</em>) – contains the name of traceable sub modules</p></li>
<li><p><strong>fx_op_cfgs</strong> (<em>dict</em><em>, </em><em>QConfigMapping</em>) – the configuration for prepare_fx quantization.</p></li>
<li><p><strong>model</strong> (<em>dir</em>) – input model which is PyTorch model.</p></li>
<li><p><strong>prefix</strong> (<em>string</em>) – prefix of op name</p></li>
<li><p><strong>is_qat</strong> (<em>bool</em>) – whether it is a qat quantization</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output model which is a prepared PyTorch model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>model (dir)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.convert_sub_graph">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">convert_sub_graph</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sub_module_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.convert_sub_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Static method to convert sub modules recursively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sub_module_list</strong> (<em>list</em>) – contains the name of traceable sub modules</p></li>
<li><p><strong>model</strong> (<em>dir</em>) – input model which is prepared PyTorch model.</p></li>
<li><p><strong>prefix</strong> (<em>string</em>) – prefix of op name</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output model which is a converted PyTorch int8 model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>model (dir)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.query_fw_capability">
<span class="sig-name descname"><span class="pre">query_fw_capability</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.query_fw_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function to get all quantizable ops from model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>object</em>) – input model which is Neural Compressor model</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tuning capability for each op from model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>q_capability (dictionary)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.fuse_fx_model">
<span class="sig-name descname"><span class="pre">fuse_fx_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_qat</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.fuse_fx_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a helper function to get fused fx model for PyTorch_FXAdaptor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – input model which is Neural Compressor model.</p></li>
<li><p><strong>is_qat</strong> (<em>bool</em>) – check quantization approach is qat or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>fused GraphModule model from torch.fx.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>fused_model (GraphModule)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.calculate_op_sensitivity">
<span class="sig-name descname"><span class="pre">calculate_op_sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tune_cfg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_op_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_batches</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fallback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">requantize_cfgs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.calculate_op_sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>This is a helper function for <cite>query_fw_capability</cite>,</dt><dd><p>and it will get all quantizable ops from model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – INC model containing fp32 model</p></li>
<li><p><strong>dataloader</strong> (<em>string</em>) – dataloader contains real data.</p></li>
<li><p><strong>tune_cfg</strong> (<em>dict</em>) – dictionary of tune configure for each op.</p></li>
<li><p><strong>fallback</strong> (<em>bool</em>) – switch method in fallback stage and re-quantize stage</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>sorted op list by sensitivity</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ops_lst (list)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchQuery">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">neural_compressor.adaptor.pytorch.</span></span><span class="sig-name descname"><span class="pre">PyTorchQuery</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_config_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchQuery" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../query/index.html#neural_compressor.adaptor.query.QueryBackendCapability" title="neural_compressor.adaptor.query.QueryBackendCapability"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neural_compressor.adaptor.query.QueryBackendCapability</span></code></a></p>
<p>Base class that defines Query Interface.
Each adaption layer should implement the inherited class for specific backend on their own.</p>
<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchQuery.get_quantization_capability">
<span class="sig-name descname"><span class="pre">get_quantization_capability</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_quantization_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types’ quantization capability.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of dictionary which key is precision
and value is a dict that describes all op types’ quantization capability.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types">
<span class="sig-name descname"><span class="pre">get_op_types</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the supported op types by all precisions.
:returns: A list composed of dictionary which key is precision</p>
<blockquote>
<div><p>and value is the op types.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>[dictionary list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types_by_precision">
<span class="sig-name descname"><span class="pre">get_op_types_by_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">precision</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types_by_precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Get op types per precision
:param precision: precision name
:type precision: string</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A list composed of op type.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>[string list]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Intel® Neural Compressor.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">neural_compressor.adaptor.pytorch</span></code></a><ul>
<li><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li><a class="reference internal" href="#classes">Classes</a></li>
<li><a class="reference internal" href="#functions">Functions</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.get_ops_recursively"><code class="docutils literal notranslate"><span class="pre">get_ops_recursively()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor"><code class="docutils literal notranslate"><span class="pre">TemplateAdaptor</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.is_fused_module"><code class="docutils literal notranslate"><span class="pre">TemplateAdaptor.is_fused_module()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.calculate_hessian_trace"><code class="docutils literal notranslate"><span class="pre">TemplateAdaptor.calculate_hessian_trace()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.quantize"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.quantize()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.evaluate"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.train"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.train()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_child"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.is_fused_child()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_op"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.is_fused_op()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_last_fused_child"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.is_last_fused_child()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.save"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.save()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.inspect_tensor"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.inspect_tensor()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.set_tensor"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.set_tensor()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.query_fw_capability"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.query_fw_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.get_non_quant_modules"><code class="docutils literal notranslate"><span class="pre">PyTorchAdaptor.get_non_quant_modules()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.quantize"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor.quantize()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.evaluate"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.query_fw_capability"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor.query_fw_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.save"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor.save()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.inspect_tensor"><code class="docutils literal notranslate"><span class="pre">PyTorch_IPEXAdaptor.inspect_tensor()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.quantize"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.quantize()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.evaluate"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.train"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.train()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.prepare_sub_graph"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.prepare_sub_graph()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.convert_sub_graph"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.convert_sub_graph()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.query_fw_capability"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.query_fw_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.fuse_fx_model"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.fuse_fx_model()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.calculate_op_sensitivity"><code class="docutils literal notranslate"><span class="pre">PyTorch_FXAdaptor.calculate_op_sensitivity()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery"><code class="docutils literal notranslate"><span class="pre">PyTorchQuery</span></code></a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_quantization_capability"><code class="docutils literal notranslate"><span class="pre">PyTorchQuery.get_quantization_capability()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types"><code class="docutils literal notranslate"><span class="pre">PyTorchQuery.get_op_types()</span></code></a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types_by_precision"><code class="docutils literal notranslate"><span class="pre">PyTorchQuery.get_op_types_by_precision()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.get_ops_recursively">get_ops_recursively</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor">TemplateAdaptor</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.is_fused_module">is_fused_module</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.TemplateAdaptor.calculate_hessian_trace">calculate_hessian_trace</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor">PyTorchAdaptor</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.quantize">quantize</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.evaluate">evaluate</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.train">train</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_child">is_fused_child</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_fused_op">is_fused_op</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.is_last_fused_child">is_last_fused_child</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.save">save</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.inspect_tensor">inspect_tensor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.set_tensor">set_tensor</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.query_fw_capability">query_fw_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchAdaptor.get_non_quant_modules">get_non_quant_modules</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor">PyTorch_IPEXAdaptor</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.quantize">quantize</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.evaluate">evaluate</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.query_fw_capability">query_fw_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.save">save</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor.inspect_tensor">inspect_tensor</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor">PyTorch_FXAdaptor</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.quantize">quantize</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.evaluate">evaluate</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.train">train</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.prepare_sub_graph">prepare_sub_graph</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.convert_sub_graph">convert_sub_graph</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.query_fw_capability">query_fw_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.fuse_fx_model">fuse_fx_model</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor.calculate_op_sensitivity">calculate_op_sensitivity</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery">PyTorchQuery</a><ul>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_quantization_capability">get_quantization_capability</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types">get_op_types</a></li>
<li><a class="reference internal" href="#neural_compressor.adaptor.pytorch.PyTorchQuery.get_op_types_by_precision">get_op_types_by_precision</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../../_static/sphinx_highlight.js"></script>

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 
<script script type="text/javascript">
  var collapsedSections = ['start', 'autoapi', 'info'];
</script>



  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Lorem ipsum dolor sit amet, consectetur</p>
          <a class="with-right-arrow" href="https://shiftlab.github.io/pytorch/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://shiftlab.github.io/pytorch/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/">PyTorch</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/get-started">Get Started</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/features">Features</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/ecosystem">Ecosystem</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/blog/">Blog</a></li>
            <li><a href="https://shiftlab.github.io/pytorch/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://shiftlab.github.io/pytorch/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://shiftlab.github.io/pytorch/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://shiftlab.github.io/pytorch/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>